{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "brbAhqfhE42-"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "\n",
        "from torch.utils.data import DataLoader\n",
        "from torch.utils.data import sampler\n",
        "import torchvision.datasets as datasets\n",
        "import torchvision.transforms as T\n",
        "from torchvision import models\n",
        "import matplotlib.pyplot as plt"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "DATA_PATH = '/sample_data/cifar-10-batches-py'\n",
        "NUM_TRAIN = 45000\n",
        "MINIBATCH_SIZE = 64\n",
        "transform_imagenet = T.Compose([\n",
        "                T.Resize(224),\n",
        "                T.ToTensor(),\n",
        "                T.Normalize((0.485, 0.456, 0.406), (0.229, 0.224, 0.225))\n",
        "            ])\n",
        "\n",
        "transform_cifar = T.Compose([\n",
        "                T.ToTensor(),\n",
        "                T.Normalize([0.491, 0.482, 0.447], [0.247, 0.243, 0.261])\n",
        "            ])\n",
        "\n",
        "cifar10_train = datasets.CIFAR10(DATA_PATH, train=True, download=True,\n",
        "                             transform=transform_imagenet)\n",
        "train_loader = DataLoader(cifar10_train, batch_size=MINIBATCH_SIZE, \n",
        "                          sampler=sampler.SubsetRandomSampler(range(NUM_TRAIN)))\n",
        "\n",
        "\n",
        "cifar10_val = datasets.CIFAR10(DATA_PATH, train=True, download=True,\n",
        "                           transform=transform_imagenet)\n",
        "val_loader = DataLoader(cifar10_val, batch_size=MINIBATCH_SIZE, \n",
        "                        sampler=sampler.SubsetRandomSampler(range(NUM_TRAIN, len(cifar10_val))))\n",
        "\n",
        "\n",
        "cifar10_test = datasets.CIFAR10(DATA_PATH, train=False, download=True, \n",
        "                            transform=transform_imagenet)\n",
        "test_loader = DataLoader(cifar10_test, batch_size=MINIBATCH_SIZE)"
      ],
      "metadata": {
        "id": "YiKkMW40GO61"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "if torch.cuda.is_available():\n",
        "    device = torch.device('cuda')\n",
        "else:\n",
        "    device = torch.device('cpu')\n",
        "\n",
        "print(device)"
      ],
      "metadata": {
        "id": "U2BA53XYGPV9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "classes = ['Plane', 'Car', 'Bird', 'Cat', 'Deer','Dog', 'Frog', 'Horse', 'Ship', 'Truck']\n",
        "\n",
        "def plot_figure(image):\n",
        "    plt.imshow(image.permute(1,2,0))\n",
        "    plt.axis('off')\n",
        "    plt.show()\n",
        "\n",
        "rnd_sample_idx = np.random.randint(len(test_loader))\n",
        "print(f'La imagen muestreada representa un: {classes[test_loader.dataset[rnd_sample_idx][1]]}')\n",
        "image = test_loader.dataset[rnd_sample_idx][0]\n",
        "image = (image - image.min()) / (image.max() -image.min() )\n",
        "plot_figure(image)"
      ],
      "metadata": {
        "id": "rwr1H_p8GPYn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def accuracy(model, loader):\n",
        "    num_correct = 0\n",
        "    num_total = 0\n",
        "    model.eval()\n",
        "    model = model.to(device=device)\n",
        "    with torch.no_grad():\n",
        "        for (xi, yi) in loader:\n",
        "            xi = xi.to(device=device, dtype = torch.float32)\n",
        "            yi = yi.to(device=device, dtype = torch.long)\n",
        "            scores = model(xi) \n",
        "            _, pred = scores.max(dim=1) \n",
        "            num_correct += (pred == yi).sum() \n",
        "            num_total += pred.size(0)\n",
        "        return float(num_correct)/num_total "
      ],
      "metadata": {
        "id": "XREKi-dmGPbi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model_resnet18 = models.resnet18(pretrained=True)"
      ],
      "metadata": {
        "id": "kEVWt7gZGPeU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model_aux = nn.Sequential(*list(model_resnet18.children()))"
      ],
      "metadata": {
        "id": "Za6q3VXGGPhR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model_aux = nn.Sequential(*list(model_resnet18.children())[:-1])"
      ],
      "metadata": {
        "id": "_QOpC0JnGm9O"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for i, parameter in enumerate(model_aux.parameters()):\n",
        "    parameter.requires_grad = False"
      ],
      "metadata": {
        "id": "F7Rb1Qf_GnCV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def train(model, optimiser, epochs=100):\n",
        "    model = model.to(device=device)\n",
        "    for epoch in range(epochs):\n",
        "        for i, (xi, yi) in enumerate(train_loader):\n",
        "            model.train()\n",
        "            xi = xi.to(device=device, dtype=torch.float32)\n",
        "            yi = yi.to(device=device, dtype=torch.long)\n",
        "            scores = model(xi)\n",
        "\n",
        "            cost = F.cross_entropy(input= scores, target=yi)\n",
        "        \n",
        "            optimiser.zero_grad()           \n",
        "            cost.backward()\n",
        "            optimiser.step()           \n",
        "            \n",
        "        acc = accuracy(model, val_loader)\n",
        "        print(f'Epoch: {epoch}, costo: {cost.item()}, accuracy: {acc},')"
      ],
      "metadata": {
        "id": "22Ee617-GnFe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "hidden1 = 256 \n",
        "hidden = 256\n",
        "lr = 5e-4\n",
        "epochs = 5\n",
        "model1 = nn.Sequential(model_aux,\n",
        "                       nn.Flatten(), \n",
        "                       nn.Linear(in_features=512, out_features= 10, bias= True))\n",
        "optimiser = torch.optim.Adam(model1.parameters(), lr=lr, betas=(0.9, 0.999))"
      ],
      "metadata": {
        "id": "bg1guItQHE7F"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train(model1, optimiser, epochs)"
      ],
      "metadata": {
        "id": "scPWrkocHE-N"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "accuracy(model1, test_loader)"
      ],
      "metadata": {
        "id": "iCjRsXg7HFBT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "jEWcNEVEHFD6"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}