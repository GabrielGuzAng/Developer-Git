{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RU5N8ddBNQ0i"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "#PyTorch stuff\n",
        "import torch\n",
        "torch.manual_seed(0)\n",
        "from torch import optim, nn\n",
        "from torch.nn import functional as F\n",
        "from torchvision import transforms as T\n",
        "from torchvision import models, datasets\n",
        "from torch.utils.data import DataLoader, Dataset, random_split"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "print(device)"
      ],
      "metadata": {
        "id": "UdA9xYt6Nd3h"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "PATH = '/sample_data/cifar-10'\n",
        "TRAIN_SIZE = 50000\n",
        "VAL_SIZE = 5000\n",
        "TEST_SIZE = 5000\n",
        "MINIBATCH_SIZE = 512\n",
        "\n",
        "transform_cifar10_train = T.Compose([\n",
        "                T.RandomHorizontalFlip(p=0.3),\n",
        "                T.ColorJitter(brightness=0.1, contrast=0.1, hue = 0.05),\n",
        "                T.RandomApply([T.RandomRotation(10), T.Resize(40), T.CenterCrop(32)], p = 0.1),\n",
        "                T.ToTensor(),\n",
        "                T.Normalize([0.491, 0.482, 0.447], [0.247, 0.243, 0.262])\n",
        "            ])\n",
        "transform_cifar10_test = T.Compose([\n",
        "                T.ToTensor(),\n",
        "                T.Normalize([0.491, 0.482, 0.447], [0.247, 0.243, 0.262])\n",
        "            ])\n",
        "\n",
        "# Training set loader\n",
        "cifar10_train = datasets.CIFAR10(PATH, train=True, download=True,transform=transform_cifar10_train)\n",
        "train_loader = DataLoader(cifar10_train, batch_size=MINIBATCH_SIZE, shuffle = True)\n",
        "\n",
        "# Validation and test sets\n",
        "test_dataset = datasets.CIFAR10(PATH, train=False, download=True, transform=transform_cifar10_test)\n",
        "val_dataset, test_dataset = random_split(test_dataset, [VAL_SIZE, TEST_SIZE])\n",
        "\n",
        "val_loader = DataLoader(val_dataset, batch_size=MINIBATCH_SIZE, shuffle = True)\n",
        "\n",
        "test_loader = DataLoader(test_dataset, batch_size=MINIBATCH_SIZE, shuffle = True)"
      ],
      "metadata": {
        "id": "t5-dUBRhNd_U"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "classes = train_loader.dataset.classes\n",
        "def plot_figure(image):\n",
        "    plt.figure(figsize=(3,3))\n",
        "    plt.imshow(np.transpose(image,(1,2,0)))\n",
        "    plt.axis('off')\n",
        "    plt.show()\n",
        "\n",
        "rnd_sample_idx = np.random.randint(len(test_loader))\n",
        "print(f'La imagen muestreada representa un: {classes[test_loader.dataset[rnd_sample_idx][1]]}')\n",
        "image = test_loader.dataset[rnd_sample_idx][0]\n",
        "image = (image - image.min()) / (image.max() -image.min() )\n",
        "plot_figure(image)"
      ],
      "metadata": {
        "id": "QzQZ6rvCNeCD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def plot_cifar10_grid():\n",
        "    classes = train_loader.dataset.classes\n",
        "    total_samples = 8\n",
        "    plt.figure(figsize=(15,15))\n",
        "    for label, sample in enumerate(classes):\n",
        "        class_idxs = np.flatnonzero(label == np.array(train_loader.dataset.targets))\n",
        "        sample_idxs = np.random.choice(class_idxs, total_samples, replace = False)\n",
        "        for i, idx in enumerate(sample_idxs):\n",
        "            plt_idx = i*len(classes) + label + 1\n",
        "            plt.subplot(total_samples, len(classes), plt_idx)\n",
        "            plt.imshow(train_loader.dataset.data[idx])\n",
        "            plt.axis('off')\n",
        "            \n",
        "            if i == 0: plt.title(sample)\n",
        "    plt.show()\n",
        "\n",
        "plot_cifar10_grid() "
      ],
      "metadata": {
        "id": "UtJOgwgUNeFE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "len(val_loader)"
      ],
      "metadata": {
        "id": "Zr1iVj_5NeH2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def accuracy(model, loader):\n",
        "    '''\n",
        "    model - PyTorch model\n",
        "    loader - PyTorch dataloader\n",
        "    \n",
        "    Returns:\n",
        "    \n",
        "    '''\n",
        "    correct = 0\n",
        "    total = 0\n",
        "    cost = 0\n",
        "    model.eval()\n",
        "    model = model.to(device=device)\n",
        "    with torch.no_grad():\n",
        "        for x, y in loader:\n",
        "            x = x.to(device=device, dtype=torch.float32)\n",
        "            y = y.to(device=device, dtype=torch.long)\n",
        "            scores = model(x)\n",
        "            cost += (F.cross_entropy(scores, y)).item()\n",
        "            _, pred = scores.max(dim=1)\n",
        "            correct += (pred == y).sum()\n",
        "            total += pred.size(0)\n",
        "        return cost/len(loader), float(correct)/total"
      ],
      "metadata": {
        "id": "8EOgDY4VSHM6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def find_lr(model, optimiser, start_val = 1e-6, end_val = 1, beta = 0.99, loader = train_loader):\n",
        "    n = len(loader) - 1\n",
        "    factor = (end_val / start_val)**(1/n)\n",
        "    lr = start_val\n",
        "    optimiser.param_groups[0]['lr'] = lr #this allows you to update the learning rate\n",
        "    avg_loss, loss, acc = 0., 0., 0.\n",
        "    lowest_loss = 0.\n",
        "    batch_num = 0\n",
        "    losses = []\n",
        "    log_lrs = []\n",
        "    accuracies = []\n",
        "    model = model.to(device=device)\n",
        "    for i, (x, y) in enumerate(loader, start=1):\n",
        "        x = x.to(device = device, dtype = torch.float32)\n",
        "        y = y.to(device = device, dtype = torch.long)\n",
        "        optimiser.zero_grad()\n",
        "        scores = model(x)\n",
        "        cost = F.cross_entropy(input=scores, target=y)\n",
        "        loss = beta*loss + (1-beta)*cost.item()\n",
        "        #bias correction\n",
        "        avg_loss = loss/(1 - beta**i)\n",
        "        \n",
        "        acc_ = ((torch.argmax(scores, dim=1) == y).sum()/scores.size(0)) \n",
        "#         acc = beta*acc + (1-beta)*acc_.item()\n",
        "#         avg_acc = acc/(1 - beta**i)\n",
        "        #if loss is massive stop\n",
        "        if i > 1 and avg_loss > 4 * lowest_loss:\n",
        "            print(f'from here{i, cost.item()}')\n",
        "            return log_lrs, losses, accuracies\n",
        "        if avg_loss < lowest_loss or i == 1:\n",
        "            lowest_loss = avg_loss\n",
        "        \n",
        "#         accuracies.append(acc.item())\n",
        "        accuracies.append(acc_.item())\n",
        "#         accuracies.append(avg_acc)\n",
        "        losses.append(avg_loss)\n",
        "        log_lrs.append(lr)\n",
        "        #step\n",
        "        cost.backward()\n",
        "        optimiser.step()\n",
        "        #update lr\n",
        "        print(f'cost:{cost.item():.4f}, lr: {lr:.4f}, acc: {acc_.item():.4f}')\n",
        "        lr *= factor\n",
        "        optimiser.param_groups[0]['lr'] = lr\n",
        "        \n",
        "    return log_lrs, losses, accuracies     "
      ],
      "metadata": {
        "id": "OAe_jC8pSHPr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def train(model, optimiser, scheduler = None, epochs = 100):\n",
        "    model = model.to(device = device)\n",
        "    val_loss_history = []\n",
        "    train_loss_history = []\n",
        "    val_acc_history = []\n",
        "    train_acc_history = []\n",
        "    lrs = []\n",
        "    train_cost = 0.\n",
        "    val_cost = 0.\n",
        "    train_cost_acum = 0\n",
        "    for epoch in range(epochs):\n",
        "        train_correct_num  = 0\n",
        "        train_total = 0\n",
        "        train_cost_acum = 0\n",
        "        for mb, (x, y) in enumerate(train_loader, start=1):\n",
        "            model.train()\n",
        "            x = x.to(device=device, dtype=torch.float32)\n",
        "            y = y.to(device=device, dtype=torch.long)\n",
        "            scores = model(x)\n",
        "            cost = F.cross_entropy(input=scores, target=y)\n",
        "            optimiser.zero_grad()\n",
        "            cost.backward()\n",
        "            optimiser.step()\n",
        "            #if using scheduler\n",
        "            if scheduler: scheduler.step()\n",
        "                \n",
        "            train_correct_num += (torch.argmax(scores, dim=1) == y).sum()\n",
        "            train_total += scores.size(0)        \n",
        "            train_cost_acum += cost.item()\n",
        "            train_acc = float(train_correct_num)/train_total  \n",
        "#             train_cost = train_cost_acum/mb\n",
        "            val_cost, val_acc = accuracy(model, val_loader)\n",
        "\n",
        "            val_loss_history.append(val_cost)\n",
        "            train_loss_history.append(cost.item())\n",
        "            val_acc_history.append(val_acc)\n",
        "            train_acc_history.append(train_acc)\n",
        "#             lrs.append(scheduler.get_last_lr()[0])\n",
        "            lrs.append(optimiser.param_groups[0][\"lr\"])\n",
        "        \n",
        "        #f'last lr: {scheduler.get_last_lr()[0]:6f},\n",
        "        \n",
        "        train_acc = float(train_correct_num)/train_total\n",
        "        train_cost = train_cost_acum/len(train_loader)\n",
        "        print(f'Epoch:{epoch}, train cost: {train_cost:.6f}, val cost: {val_cost:.6f},'\n",
        "                      f' train acc: {train_acc:.4f}, val acc: {val_acc:4f}, total: {train_total},'\n",
        "                      f' lr: {optimiser.param_groups[0][\"lr\"]:.6f}')\n",
        "        \n",
        "    return train_loss_history, val_loss_history, train_acc_history, val_acc_history, lrs"
      ],
      "metadata": {
        "id": "y2gsqJh1SHS5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "conv_k_3 = lambda channel1, channel2, stride: nn.Conv2d(channel1, channel2, stride = stride, kernel_size=3, padding=1)"
      ],
      "metadata": {
        "id": "MMbpsC6iSHV9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class residual_block(nn.Module):\n",
        "    '''\n",
        "\n",
        "    '''\n",
        "    def __init__(self, in_channel, out_channel, stride=1, change_size = True):\n",
        "        super().__init__()\n",
        "        self.conv1 = conv_k_3(in_channel, out_channel, stride)\n",
        "        self.bn1 = nn.BatchNorm2d(out_channel)\n",
        "        self.conv2 = conv_k_3(out_channel, out_channel, 1)\n",
        "        self.bn2 = nn.BatchNorm2d(out_channel)\n",
        "        #for changing activation map sizes\n",
        "        self.change_size = change_size\n",
        "        if change_size:\n",
        "            self.residual = nn.Sequential(nn.Conv2d(in_channel, \n",
        "                                                    out_channel, \n",
        "                                                    kernel_size=1,\n",
        "                                                    stride=stride),\n",
        "                                         nn.BatchNorm2d(out_channel)\n",
        "                                         )      \n",
        "    def forward(self, x):\n",
        "        identity = x if not self.change_size else self.residual(x)\n",
        "        y = F.relu(self.bn1(self.conv1(x)))\n",
        "        y = self.bn2(self.conv2(y))\n",
        "        y += identity\n",
        "        return F.relu(y)"
      ],
      "metadata": {
        "id": "-Mm0YzWGSHY5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class ResNet56(nn.Module):\n",
        "    def __init__(self, n=9, num_classes=10):\n",
        "        super().__init__()\n",
        "        self.conv1 = conv_k_3(3, 16, stride = 1)\n",
        "        self.bn1 = nn.BatchNorm2d(16)\n",
        "        self.block1 = self.create_block(n=9, in_channel=16, \n",
        "                                        out_channel=16, stride=1, \n",
        "                                        change_size=False)\n",
        "        self.block2 = self.create_block(n=9, in_channel=16, \n",
        "                                        out_channel=32, stride=2)\n",
        "        self.block3 = self.create_block(n=9, in_channel=32, \n",
        "                                        out_channel=64, stride=2)\n",
        "        self.fc = nn.Linear(64, num_classes)\n",
        "\n",
        "    def create_block(self, n, in_channel, out_channel, stride, change_size=True):\n",
        "        block = [residual_block(in_channel, out_channel, stride, change_size=change_size)]\n",
        "        for i in range(n-1):\n",
        "            block.append(residual_block(out_channel, out_channel, stride=1, change_size=False))\n",
        "        return nn.Sequential(*block)   \n",
        "        \n",
        "    def forward(self, x):\n",
        "        y = F.relu(self.bn1(self.conv1(x)))\n",
        "        y = self.block3(self.block2(self.block1(y)))\n",
        "        y = F.adaptive_avg_pool2d(y, 1)\n",
        "        return self.fc(y.view(y.size(0), -1))      "
      ],
      "metadata": {
        "id": "hRyEwoOtSHbd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model_resnet56 = ResNet56()"
      ],
      "metadata": {
        "id": "BjXvL5O1NeKp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "optimiser_resnet56 = torch.optim.SGD(model_resnet56.parameters(),\n",
        "                                     lr=0.1, momentum=0.95,\n",
        "                                     weight_decay=1e-4)"
      ],
      "metadata": {
        "id": "C-Bgmc16dJHv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "lg_lr, losses, accuracies = find_lr(model_resnet56, optimiser_resnet56,\n",
        "                                    start_val=1e-6, end_val=10)"
      ],
      "metadata": {
        "id": "B6XjUOoAdOxE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "f1, ax1 = plt.subplots(figsize=(20,10))\n",
        "# ax1.plot(lr[60:-2], losses[60:-2])\n",
        "ax1.plot(lg_lr, losses)\n",
        "ax1.set_xscale('log')\n",
        "ax1.set_xticks([1e-1,2e-1, 1, 10])\n",
        "ax1.get_xaxis().get_major_formatter().labelOnlyBase = False\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "LJZv8GzreQI5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "f1, ax1 = plt.subplots(figsize=(20,10))\n",
        "# ax1.plot(lr[60:-2], losses[60:-2])\n",
        "ax1.plot(lg_lr, accuracies)\n",
        "ax1.set_xscale('log')\n",
        "# ax1.set_xticks([1e-1, 2e-1,5e-1, 7e-1, 1, 10])\n",
        "ax1.get_xaxis().get_major_formatter().labelOnlyBase = False\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "F-lTVzVPeT7l"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model_resnet56 = ResNet56()\n",
        "optimiser_resnet56 = torch.optim.SGD(model_resnet56.parameters(),\n",
        "                                     lr=0.1, momentum=0.95,\n",
        "                                     weight_decay=1e-4)\n",
        "epochs = 50\n",
        "scheduler = torch.optim.lr_scheduler.OneCycleLR(optimiser_resnet56, \n",
        "                                                max_lr=2e-1, \n",
        "                                                steps_per_epoch=len(train_loader), \n",
        "                                                epochs = epochs, pct_start=0.43, \n",
        "                                                div_factor=10, \n",
        "                                                final_div_factor=1000, \n",
        "                                                three_phase=True, verbose=False\n",
        "                                            )\n",
        "train_loss_history, val_loss_history, train_acc_history, val_acc_history, lrs = train(\n",
        "                                model_resnet56, \n",
        "                                optimiser=optimiser_resnet56,\n",
        "                                scheduler=scheduler,\n",
        "                                epochs = epochs\n",
        "                                )"
      ],
      "metadata": {
        "id": "q1Q-lsEQecTc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "accuracy(model_resnet56, test_loader)"
      ],
      "metadata": {
        "id": "WFtD41cjgXUT"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}