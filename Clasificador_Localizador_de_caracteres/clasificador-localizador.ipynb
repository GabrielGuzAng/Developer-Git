{"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.10.14"},"accelerator":"GPU","colab":{"collapsed_sections":["ld4KujWxIFKw"],"gpuType":"T4","provenance":[]},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[{"sourceId":9993222,"sourceType":"datasetVersion","datasetId":6150471}],"dockerImageVersionId":30787,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"#import nbimporter\nimport pickle\nimport zipfile\nimport datetime\nimport string\nimport glob\nimport math\nimport os\nimport tqdm\nimport matplotlib.pyplot as plt\nimport tensorflow as tf\nimport sklearn.model_selection\nimport traceback\nimport kagglehub\n#assert tf.test.is_gpu_available()\nimport random\nimport string\nimport numpy as np\nimport cv2\nfrom sklearn.preprocessing import LabelEncoder\nimport PIL\nimport pickle\nfrom PIL import Image,ImageOps\nfrom tensorflow.keras.preprocessing.image import img_to_array, array_to_img\nimport gc\nfrom PIL import Image,ImageOps","metadata":{"execution":{"iopub.status.busy":"2024-12-05T22:26:00.705771Z","iopub.execute_input":"2024-12-05T22:26:00.706077Z","iopub.status.idle":"2024-12-05T22:26:15.495000Z","shell.execute_reply.started":"2024-12-05T22:26:00.706047Z","shell.execute_reply":"2024-12-05T22:26:15.494007Z"},"id":"cBkAqikKN3zM","trusted":true},"outputs":[],"execution_count":1},{"cell_type":"code","source":"from tensorflow.keras.utils import to_categorical","metadata":{"execution":{"iopub.status.busy":"2024-12-05T22:32:04.656110Z","iopub.execute_input":"2024-12-05T22:32:04.657065Z","iopub.status.idle":"2024-12-05T22:32:04.667472Z","shell.execute_reply.started":"2024-12-05T22:32:04.657028Z","shell.execute_reply":"2024-12-05T22:32:04.666743Z"},"trusted":true},"outputs":[],"execution_count":2},{"cell_type":"markdown","source":"# Cargar dataset","metadata":{"id":"olzTAR-cvXe3"}},{"cell_type":"code","source":"char_coordinates_images_path = kagglehub.dataset_download('gabrielguz/char-coordinates-images')","metadata":{"execution":{"iopub.status.busy":"2024-12-05T22:32:04.668756Z","iopub.execute_input":"2024-12-05T22:32:04.669025Z","iopub.status.idle":"2024-12-05T22:32:05.188544Z","shell.execute_reply.started":"2024-12-05T22:32:04.668998Z","shell.execute_reply":"2024-12-05T22:32:05.187885Z"},"trusted":true},"outputs":[],"execution_count":3},{"cell_type":"code","source":"def load_dataset(dataset_name):\n    # Define the paths to the images and labels\n    images_dir = os.path.join(dataset_name, 'images')\n    labels_path = os.path.join(dataset_name, 'labels.pkl')\n\n    # Load the labels from the pickle file\n    with open(labels_path, 'rb') as f:\n        labels = pickle.load(f)\n\n    # Get a sorted list of image filenames\n    image_files = sorted(os.listdir(images_dir), key=lambda x: int(x.split('_')[1].split('.')[0]))\n\n    # Load the images\n    images = []\n    for image_file in image_files:\n        image_path = os.path.join(images_dir, image_file)\n        image = Image.open(image_path)\n        images.append(image)\n\n    return images, labels","metadata":{"execution":{"iopub.status.busy":"2024-12-05T22:32:05.189797Z","iopub.execute_input":"2024-12-05T22:32:05.190021Z","iopub.status.idle":"2024-12-05T22:32:05.195524Z","shell.execute_reply.started":"2024-12-05T22:32:05.189999Z","shell.execute_reply":"2024-12-05T22:32:05.194636Z"},"id":"21YJpGo9mt2S","trusted":true},"outputs":[],"execution_count":4},{"cell_type":"code","source":"char_coordinates_images_path='/kaggle/input/char-coordinates-images/content/dataset_abc'\ndata, labels = load_dataset(char_coordinates_images_path)\nprint(f'Number of images: {len(data)}')\nprint(f'Number of labels: {len(labels)}')","metadata":{"execution":{"iopub.status.busy":"2024-12-05T22:32:05.196434Z","iopub.execute_input":"2024-12-05T22:32:05.196671Z","iopub.status.idle":"2024-12-05T22:34:37.383675Z","shell.execute_reply.started":"2024-12-05T22:32:05.196648Z","shell.execute_reply":"2024-12-05T22:34:37.382750Z"},"trusted":true},"outputs":[{"name":"stdout","text":"Number of images: 30873\nNumber of labels: 30873\n","output_type":"stream"}],"execution_count":5},{"cell_type":"code","source":"\nnum_samples = len(data)\nindices = np.arange(num_samples)\nnp.random.shuffle(indices)\n\n# Randomizo\ndata = [data[i] for i in indices]\nlabels = [labels[i] for i in indices]","metadata":{"execution":{"iopub.status.busy":"2024-12-05T22:34:37.386150Z","iopub.execute_input":"2024-12-05T22:34:37.386894Z","iopub.status.idle":"2024-12-05T22:34:37.406602Z","shell.execute_reply.started":"2024-12-05T22:34:37.386862Z","shell.execute_reply":"2024-12-05T22:34:37.405744Z"},"trusted":true},"outputs":[],"execution_count":6},{"cell_type":"code","source":"num_samples = len(data)\ndata = data[0:len(data)//2]\nlabels= labels[ 0:len(labels)//2]","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-05T22:34:37.407925Z","iopub.execute_input":"2024-12-05T22:34:37.408314Z","iopub.status.idle":"2024-12-05T22:34:37.597784Z","shell.execute_reply.started":"2024-12-05T22:34:37.408261Z","shell.execute_reply":"2024-12-05T22:34:37.596983Z"}},"outputs":[],"execution_count":7},{"cell_type":"code","source":"num_samples = len(data)\ntrain_size = int(0.7 * num_samples)\nval_size = int(0.2 * num_samples)\ntest_size = num_samples - train_size - val_size  ","metadata":{"execution":{"iopub.status.busy":"2024-12-05T22:34:37.598990Z","iopub.execute_input":"2024-12-05T22:34:37.599226Z","iopub.status.idle":"2024-12-05T22:34:37.603304Z","shell.execute_reply.started":"2024-12-05T22:34:37.599204Z","shell.execute_reply":"2024-12-05T22:34:37.602576Z"},"trusted":true},"outputs":[],"execution_count":8},{"cell_type":"code","source":"image_sizes=(data[0].size)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-05T23:52:08.521498Z","iopub.execute_input":"2024-12-05T23:52:08.522248Z","iopub.status.idle":"2024-12-05T23:52:08.526669Z","shell.execute_reply.started":"2024-12-05T23:52:08.522203Z","shell.execute_reply":"2024-12-05T23:52:08.525632Z"}},"outputs":[],"execution_count":41},{"cell_type":"code","source":"print(image_sizes)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-05T23:52:20.486857Z","iopub.execute_input":"2024-12-05T23:52:20.487209Z","iopub.status.idle":"2024-12-05T23:52:20.492112Z","shell.execute_reply.started":"2024-12-05T23:52:20.487180Z","shell.execute_reply":"2024-12-05T23:52:20.491172Z"}},"outputs":[{"name":"stdout","text":"(244, 244)\n","output_type":"stream"}],"execution_count":42},{"cell_type":"code","source":"# Conjunto de entrenamiento\ndata_train = data[:train_size]\nlabels_train = labels[:train_size]\n\n# Conjunto de validación\ndata_val = data[train_size:train_size + val_size]\nlabels_val = labels[train_size:train_size + val_size]\n\n# Conjunto de prueba\ndata_test = data[train_size + val_size:]\nlabels_test = labels[train_size + val_size:]","metadata":{"execution":{"iopub.status.busy":"2024-12-05T22:34:37.604494Z","iopub.execute_input":"2024-12-05T22:34:37.605072Z","iopub.status.idle":"2024-12-05T22:34:37.619475Z","shell.execute_reply.started":"2024-12-05T22:34:37.605034Z","shell.execute_reply":"2024-12-05T22:34:37.618488Z"},"trusted":true},"outputs":[],"execution_count":9},{"cell_type":"code","source":"print(f\"Número de tamaño de entrenamiento: {train_size}\\n\")\nprint(f\"Número de tamaño de validación: {val_size}\\n\")\nprint(f\"Número de tamaño de prueba: {test_size}\\n\")\nprint(f\"Número de imágenes de entrenamiento: {len(data_train)}\\n\")\nprint(f\"Número de imágenes de validación: {len(data_val)}\\n\")\nprint(f\"Número de imágenes de prueba: {len(data_test)}\\n\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-05T22:34:37.620534Z","iopub.execute_input":"2024-12-05T22:34:37.621000Z","iopub.status.idle":"2024-12-05T22:34:37.630227Z","shell.execute_reply.started":"2024-12-05T22:34:37.620965Z","shell.execute_reply":"2024-12-05T22:34:37.629388Z"}},"outputs":[{"name":"stdout","text":"Número de tamaño de entrenamiento: 10805\n\nNúmero de tamaño de validación: 3087\n\nNúmero de tamaño de prueba: 1544\n\nNúmero de imágenes de entrenamiento: 10805\n\nNúmero de imágenes de validación: 3087\n\nNúmero de imágenes de prueba: 1544\n\n","output_type":"stream"}],"execution_count":10},{"cell_type":"code","source":"def verificar_data_no_nulo(a, b, c,d,e,f):\n    if a == 0 or b == 0 or c == 0 or (a!=d) or (b!=e) or (c!=f):\n        raise ValueError(\"Error: Una o más variables son cero\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-05T22:34:37.631205Z","iopub.execute_input":"2024-12-05T22:34:37.631444Z","iopub.status.idle":"2024-12-05T22:34:37.640338Z","shell.execute_reply.started":"2024-12-05T22:34:37.631418Z","shell.execute_reply":"2024-12-05T22:34:37.639637Z"}},"outputs":[],"execution_count":11},{"cell_type":"code","source":"verificar_data_no_nulo(len(data_test),len(data_train),len(data_val),len(labels_test),len(labels_train),len(labels_val))","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-05T22:34:37.643609Z","iopub.execute_input":"2024-12-05T22:34:37.643929Z","iopub.status.idle":"2024-12-05T22:34:37.649709Z","shell.execute_reply.started":"2024-12-05T22:34:37.643905Z","shell.execute_reply":"2024-12-05T22:34:37.649048Z"}},"outputs":[],"execution_count":12},{"cell_type":"code","source":"\ntrain_image_dir = 'train_images'\nval_image_dir = 'val_images'\ntest_image_dir = 'test_images'\n\nos.makedirs(train_image_dir, exist_ok=True)\nos.makedirs(val_image_dir, exist_ok=True)\nos.makedirs(test_image_dir, exist_ok=True)","metadata":{"execution":{"iopub.status.busy":"2024-12-05T22:34:37.650473Z","iopub.execute_input":"2024-12-05T22:34:37.650703Z","iopub.status.idle":"2024-12-05T22:34:37.659997Z","shell.execute_reply.started":"2024-12-05T22:34:37.650667Z","shell.execute_reply":"2024-12-05T22:34:37.659201Z"},"trusted":true},"outputs":[],"execution_count":13},{"cell_type":"code","source":"# Guardar imágenes y obtener rutas\ndef save_images(data_subset, image_dir):\n    image_paths = []\n    for idx, img in enumerate(data_subset):\n        image_path = os.path.join(image_dir, f'image_{idx}.png')\n        img.save(image_path)\n        image_paths.append(image_path)\n    return image_paths\n\ntrain_image_paths = save_images(data_train, train_image_dir)\nval_image_paths = save_images(data_val, val_image_dir)\ntest_image_paths = save_images(data_test, test_image_dir)\n","metadata":{"execution":{"iopub.status.busy":"2024-12-05T22:34:37.661118Z","iopub.execute_input":"2024-12-05T22:34:37.661384Z","iopub.status.idle":"2024-12-05T22:40:25.471661Z","shell.execute_reply.started":"2024-12-05T22:34:37.661361Z","shell.execute_reply":"2024-12-05T22:40:25.470727Z"},"trusted":true},"outputs":[],"execution_count":14},{"cell_type":"code","source":"#Nuevo\n# Paso 5: Preparar las etiquetas\nlabels_train_class = [label[0] for label in labels_train]\nlabels_val_class = [label[0] for label in labels_val]\nlabels_test_class = [label[0] for label in labels_test]\n\n# Extraer las coordenadas\nlabels_train_coords = [label[1] for label in labels_train]\nlabels_val_coords = [label[1] for label in labels_val]\nlabels_test_coords = [label[1] for label in labels_test]","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-05T22:40:25.472862Z","iopub.execute_input":"2024-12-05T22:40:25.473186Z","iopub.status.idle":"2024-12-05T22:40:25.485744Z","shell.execute_reply.started":"2024-12-05T22:40:25.473155Z","shell.execute_reply":"2024-12-05T22:40:25.484641Z"}},"outputs":[],"execution_count":15},{"cell_type":"code","source":"label_encoder = LabelEncoder()\nlabels_all_classes = labels_train_class + labels_val_class + labels_test_class\nlabels_encoded = label_encoder.fit_transform(labels_all_classes)\nnum_classes = len(label_encoder.classes_)\n\n# Dividir las etiquetas codificadas\nlabels_train_encoded = labels_encoded[:train_size]\nlabels_val_encoded = labels_encoded[train_size:train_size + val_size]\nlabels_test_encoded = labels_encoded[train_size + val_size:]\n\n# Convertir a one-hot encoding\nlabels_train_one_hot = to_categorical(labels_train_encoded, num_classes=num_classes)\nlabels_val_one_hot = to_categorical(labels_val_encoded, num_classes=num_classes)\nlabels_test_one_hot = to_categorical(labels_test_encoded, num_classes=num_classes)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-05T22:40:25.487083Z","iopub.execute_input":"2024-12-05T22:40:25.487506Z","iopub.status.idle":"2024-12-05T22:40:25.523309Z","shell.execute_reply.started":"2024-12-05T22:40:25.487475Z","shell.execute_reply":"2024-12-05T22:40:25.522302Z"}},"outputs":[],"execution_count":16},{"cell_type":"code","source":"print(f\"Número de imágenes de entrenamiento: {len(data_train)}\")\nprint(f\"Número de etiquetas de clase de entrenamiento: {len(labels_train_one_hot)}\")\nprint(f\"Número de coordenadas de entrenamiento: {len(labels_train_coords)}\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-05T22:40:25.524731Z","iopub.execute_input":"2024-12-05T22:40:25.525455Z","iopub.status.idle":"2024-12-05T22:40:25.533540Z","shell.execute_reply.started":"2024-12-05T22:40:25.525411Z","shell.execute_reply":"2024-12-05T22:40:25.532679Z"}},"outputs":[{"name":"stdout","text":"Número de imágenes de entrenamiento: 10805\nNúmero de etiquetas de clase de entrenamiento: 10805\nNúmero de coordenadas de entrenamiento: 10805\n","output_type":"stream"}],"execution_count":17},{"cell_type":"code","source":"from tensorflow.keras.applications.vgg16 import preprocess_input","metadata":{"execution":{"iopub.status.busy":"2024-12-05T22:40:25.534818Z","iopub.execute_input":"2024-12-05T22:40:25.535117Z","iopub.status.idle":"2024-12-05T22:40:25.551926Z","shell.execute_reply.started":"2024-12-05T22:40:25.535090Z","shell.execute_reply":"2024-12-05T22:40:25.550904Z"},"trusted":true},"outputs":[],"execution_count":18},{"cell_type":"code","source":"def normalize_coordinates(coords, original_width, original_height):\n    coords = np.array(coords, dtype='float32')\n    x_coords = coords[::2]  # Coordenadas x\n    y_coords = coords[1::2]  # Coordenadas y\n    x_coords /= original_width\n    y_coords /= original_height\n    normalized_coords = np.concatenate([x_coords, y_coords], axis=-1)\n    return normalized_coords","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-05T22:40:25.553072Z","iopub.execute_input":"2024-12-05T22:40:25.553392Z","iopub.status.idle":"2024-12-05T22:40:25.563615Z","shell.execute_reply.started":"2024-12-05T22:40:25.553362Z","shell.execute_reply":"2024-12-05T22:40:25.562744Z"}},"outputs":[],"execution_count":19},{"cell_type":"code","source":"\noriginal_image = Image.open(train_image_paths[0])\noriginal_width, original_height = original_image.size\n\n\nlabels_train_coords_normalized = [normalize_coordinates(coords, original_width, original_height) for coords in labels_train_coords]\nlabels_val_coords_normalized = [normalize_coordinates(coords, original_width, original_height) for coords in labels_val_coords]\nlabels_test_coords_normalized = [normalize_coordinates(coords, original_width, original_height) for coords in labels_test_coords]","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-05T22:40:25.565077Z","iopub.execute_input":"2024-12-05T22:40:25.565610Z","iopub.status.idle":"2024-12-05T22:40:25.672521Z","shell.execute_reply.started":"2024-12-05T22:40:25.565567Z","shell.execute_reply":"2024-12-05T22:40:25.671517Z"}},"outputs":[],"execution_count":20},{"cell_type":"code","source":"batch_size=64","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-05T22:40:25.673815Z","iopub.execute_input":"2024-12-05T22:40:25.674119Z","iopub.status.idle":"2024-12-05T22:40:25.678341Z","shell.execute_reply.started":"2024-12-05T22:40:25.674089Z","shell.execute_reply":"2024-12-05T22:40:25.677345Z"}},"outputs":[],"execution_count":21},{"cell_type":"code","source":"def create_dataset(image_paths, labels_one_hot, coords_normalized, shuffle=False):\n    image_paths_tensor = tf.constant(image_paths)\n    labels_tensor = tf.constant(labels_one_hot)\n    coords_tensor = tf.constant(coords_normalized)\n    dataset = tf.data.Dataset.from_tensor_slices((image_paths_tensor, labels_tensor, coords_tensor))\n    dataset = dataset.map(load_and_preprocess_image, num_parallel_calls=tf.data.AUTOTUNE)\n    if shuffle:\n        dataset = dataset.shuffle(buffer_size=1000)\n    dataset = dataset.batch(batch_size)\n    dataset = dataset.prefetch(tf.data.AUTOTUNE)\n    return dataset\n\n\ndef load_and_preprocess_image(image_path, label_class, coords):\n    image = tf.io.read_file(image_path)\n    image = tf.image.decode_png(image, channels=3)\n\n    image = tf.image.resize(image, [224, 224])\n    image = preprocess_input(image)\n\n    label_class = tf.cast(label_class, tf.float32)\n    coords = tf.cast(coords, tf.float32)\n    return image, {'class_output': label_class, 'bbox_output': coords}\n","metadata":{"execution":{"iopub.status.busy":"2024-12-05T23:53:24.461528Z","iopub.execute_input":"2024-12-05T23:53:24.462192Z","iopub.status.idle":"2024-12-05T23:53:24.468728Z","shell.execute_reply.started":"2024-12-05T23:53:24.462157Z","shell.execute_reply":"2024-12-05T23:53:24.467757Z"},"trusted":true},"outputs":[],"execution_count":44},{"cell_type":"code","source":"train_dataset = create_dataset(train_image_paths, labels_train_one_hot, labels_train_coords_normalized, shuffle=True)\nval_dataset = create_dataset(val_image_paths, labels_val_one_hot, labels_val_coords_normalized)\ntest_dataset = create_dataset(test_image_paths, labels_test_one_hot, labels_test_coords_normalized)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-05T23:53:28.014229Z","iopub.execute_input":"2024-12-05T23:53:28.015018Z","iopub.status.idle":"2024-12-05T23:53:28.199554Z","shell.execute_reply.started":"2024-12-05T23:53:28.014986Z","shell.execute_reply":"2024-12-05T23:53:28.198869Z"}},"outputs":[],"execution_count":45},{"cell_type":"markdown","source":"# DEFINO EL MODELO","metadata":{}},{"cell_type":"code","source":"from tensorflow.keras.applications import VGG16\nfrom tensorflow.keras import layers, models\nfrom tensorflow.keras.optimizers import Adam\nimport numpy as np\n\n# Cargar VGG16\nbase_model = VGG16(weights='imagenet', include_top=False, input_shape=(224, 224, 3))","metadata":{"execution":{"iopub.status.busy":"2024-12-05T22:40:27.140346Z","iopub.execute_input":"2024-12-05T22:40:27.140639Z","iopub.status.idle":"2024-12-05T22:40:28.304101Z","shell.execute_reply.started":"2024-12-05T22:40:27.140612Z","shell.execute_reply":"2024-12-05T22:40:28.303356Z"},"trusted":true},"outputs":[{"name":"stdout","text":"Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/vgg16/vgg16_weights_tf_dim_ordering_tf_kernels_notop.h5\n\u001b[1m58889256/58889256\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 0us/step\n","output_type":"stream"}],"execution_count":24},{"cell_type":"code","source":"from tensorflow.keras.layers import GlobalAveragePooling2D","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-05T22:40:28.305412Z","iopub.execute_input":"2024-12-05T22:40:28.306245Z","iopub.status.idle":"2024-12-05T22:40:28.311852Z","shell.execute_reply.started":"2024-12-05T22:40:28.306202Z","shell.execute_reply":"2024-12-05T22:40:28.310912Z"}},"outputs":[],"execution_count":25},{"cell_type":"code","source":"for layer in base_model.layers:\n    layer.trainable = False # Congelar las capas\n\n\nbase_output=base_model.output\n\n\n# Rama de localización\nx_loc = GlobalAveragePooling2D()(base_output)\nx_loc = layers.Dense(512)(x_loc)\nx_loc = layers.Activation('relu')(x_loc)\nx_loc = layers.BatchNormalization()(x_loc)\nx_loc = layers.Dropout(0.2)(x_loc)\n\nx_loc = layers.Dense(256)(x_loc)\nx_loc = layers.BatchNormalization()(x_loc)\nx_loc = layers.Activation('relu')(x_loc)\nx_loc = layers.Dropout(0.2)(x_loc)\n\nx_loc = layers.Dense(128)(x_loc)\nx_loc = layers.BatchNormalization()(x_loc)\nx_loc = layers.Activation('relu')(x_loc)\n\nbbox_output = layers.Dense(8, activation='sigmoid', name='bbox_output')(x_loc)\n\n# Rama de clasificación\nx_class = GlobalAveragePooling2D()(base_output)\nx_class = layers.Dense(512)(x_class)\nx_class = layers.Activation('relu')(x_class)\nx_class = layers.BatchNormalization()(x_class)\nx_class = layers.Dropout(0.5)(x_class)\n\nx_class = layers.Dense(256)(x_class)\nx_class = layers.Activation('relu')(x_class)\nx_class = layers.BatchNormalization()(x_class)\nx_class = layers.Dropout(0.3)(x_class)\n\nx_class = layers.Dense(128)(x_class)\nx_class = layers.BatchNormalization()(x_class)\nx_class = layers.Activation('relu')(x_class)\nx_class = layers.Dropout(0.2)(x_class)\n\nclass_output = layers.Dense(num_classes, activation='softmax', name='class_output')(x_class)\n\n# Crear el modelo\nmodel = models.Model(inputs=base_model.input, outputs=[bbox_output, class_output])","metadata":{"execution":{"iopub.status.busy":"2024-12-05T22:40:28.312986Z","iopub.execute_input":"2024-12-05T22:40:28.313242Z","iopub.status.idle":"2024-12-05T22:40:28.483534Z","shell.execute_reply.started":"2024-12-05T22:40:28.313218Z","shell.execute_reply":"2024-12-05T22:40:28.482845Z"},"trusted":true},"outputs":[],"execution_count":26},{"cell_type":"markdown","source":"ENTRENO PARA LOCALIZACIÓN\nIgnoro class_output","metadata":{}},{"cell_type":"code","source":"from tensorflow.keras.callbacks import EarlyStopping","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-05T22:40:35.933849Z","iopub.execute_input":"2024-12-05T22:40:35.934416Z","iopub.status.idle":"2024-12-05T22:40:35.940777Z","shell.execute_reply.started":"2024-12-05T22:40:35.934384Z","shell.execute_reply":"2024-12-05T22:40:35.940148Z"}},"outputs":[],"execution_count":28},{"cell_type":"code","source":"for layer in model.layers:\n    if 'class' in layer.name:\n        layer.trainable = False\n\n# Compilar el modelo para localización\nmodel.compile(\n    optimizer=Adam(learning_rate=0.001),\n    loss={'bbox_output': 'mean_squared_error', 'class_output': 'categorical_crossentropy'},\n    loss_weights={'bbox_output': 1.0, 'class_output': 0.0},\n    metrics={'bbox_output': 'mae'}\n)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"for layer in model.layers:\n    if 'class' in layer.name:\n        layer.trainable = False\n\n# Compilar el modelo para localización\nmodel.compile(\n    optimizer=Adam(learning_rate=0.001),\n    loss={'bbox_output': 'mean_squared_error', 'class_output': 'categorical_crossentropy'},\n    loss_weights={'bbox_output': 1.0, 'class_output': 0.0},\n    metrics={'bbox_output': 'mae'}\n)\n\n# Entrenar el modelo\nearly_stopping = EarlyStopping(monitor='val_loss', patience=5, restore_best_weights=True)\n\nhistory_loc = model.fit(\n    train_dataset,\n    epochs=20,\n    validation_data=val_dataset,\n    callbacks=[early_stopping]\n)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-05T22:40:29.003208Z","iopub.status.idle":"2024-12-05T22:40:29.003495Z","shell.execute_reply.started":"2024-12-05T22:40:29.003354Z","shell.execute_reply":"2024-12-05T22:40:29.003367Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"ENTRENO PARA CLASIFICACIÓN\nIgnoro bbox_output","metadata":{}},{"cell_type":"code","source":"for layer in model.layers:\n    if 'bbox' in layer.name:\n        layer.trainable = False\n    elif 'class' in layer.name:\n        layer.trainable = True\n\nearly_stopping = EarlyStopping(monitor='val_loss', patience=5, restore_best_weights=True)\nmodel.compile(\n    optimizer=Adam(learning_rate=0.001),\n    loss={'bbox_output': 'mean_squared_error', 'class_output': 'categorical_crossentropy'},\n    loss_weights={'bbox_output': 0.0, 'class_output': 1.0},\n    metrics={'class_output': 'accuracy'}\n)\nhistory_class = model.fit(\n    train_dataset,\n    epochs=20,\n    validation_data=val_dataset,\n    callbacks=[early_stopping]\n)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-05T22:40:29.004771Z","iopub.status.idle":"2024-12-05T22:40:29.005052Z","shell.execute_reply.started":"2024-12-05T22:40:29.004916Z","shell.execute_reply":"2024-12-05T22:40:29.004930Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"FINETUNEO","metadata":{}},{"cell_type":"code","source":"for layer in base_model.layers[-4:]:\n    layer.trainable = True","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-05T22:40:29.006202Z","iopub.status.idle":"2024-12-05T22:40:29.006480Z","shell.execute_reply.started":"2024-12-05T22:40:29.006339Z","shell.execute_reply":"2024-12-05T22:40:29.006352Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"COMPILACIÓN PREVIA","metadata":{}},{"cell_type":"code","source":"from tensorflow.keras.optimizers import Adam\n\n# Usar una tasa de aprendizaje baja para el fine-tuning\nlearning_rate = 1e-5\nearly_stopping = EarlyStopping(monitor='val_loss', patience=5, restore_best_weights=True)\nmodel.compile(\n    optimizer=Adam(learning_rate=learning_rate),\n    loss={\n        'class_output': 'categorical_crossentropy',\n        'bbox_output': 'mean_squared_error'\n    },\n    loss_weights={\n        'class_output': 2.0,\n        'bbox_output': 1.0\n    },\n    metrics={\n        'class_output': 'accuracy',\n        'bbox_output': 'mae'\n    }\n)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-05T22:40:29.007398Z","iopub.status.idle":"2024-12-05T22:40:29.007785Z","shell.execute_reply.started":"2024-12-05T22:40:29.007583Z","shell.execute_reply":"2024-12-05T22:40:29.007600Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"history_finetune = model.fit(\n    train_dataset,\n    epochs=20,\n    validation_data=val_dataset,\n    callbacks=[early_stopping]\n)\n\n# Paso 4: Evaluar el modelo\nbbox_output_mae, loss, class_output_accuracy= model.evaluate(test_dataset)\nprint(f\"Loss total en prueba: {loss}\")\nprint(f\" Accuracy: {class_output_accuracy}\")\nprint(f\" MAE: {bbox_output_mae}\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-05T22:40:29.009360Z","iopub.status.idle":"2024-12-05T22:40:29.009664Z","shell.execute_reply.started":"2024-12-05T22:40:29.009521Z","shell.execute_reply":"2024-12-05T22:40:29.009536Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"\ndef reverse_preprocess_vgg16(image, original_size):\n    \"\"\"\n    Revertir el preprocesamiento aplicado por VGG16.\n    \n    Args:\n        image (numpy.ndarray): Imagen preprocesada con VGG16 (BGR, medios restados).\n        original_size: Altura original de la imagen y Ancho original de la imagen.\n    \n    Returns:\n        numpy.ndarray: Imagen en formato RGB, valores en [0, 255], redimensionada al tamaño original.\n    \"\"\"\n    # Valores medios de ImageNet para VGG16\n    MEAN_VALUES = np.array([103.939, 116.779, 123.68])\n    \n    img = image.copy()\n    img += MEAN_VALUES\n    img = img[..., ::-1]\n    img = np.clip(img, 0, 255).astype('uint8')\n    \n    # Redimensiona a las dimensiones originales\n    img = cv2.resize(img, original_size, interpolation=cv2.INTER_LINEAR)\n    \n    return img","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"\n\ndef visualize_test_predictions(model,test_dataset,num_images_to_process = 10)\n    images_processed = 0\n    \n    for images, labels in test_dataset:\n        preds = model.predict(images)\n        preds_coords = preds[0]\n        preds_classes = preds[1]\n    \n        for i in range(len(images)):\n            if images_processed >= num_images_to_process:\n                break  # Salir del bucle si ya procesamos 5 imágenes\n        \n            img = images[i].numpy()\n            img = reverse_preprocess_vgg16(img, image_sizes)\n        \n            coords_true = labels['bbox_output'][i].numpy()\n            coords_pred = preds_coords[i]\n        \n            coords_true_scaled = coords_true.copy()\n            coords_true_scaled[:4] *= original_width  # x_coords\n            coords_true_scaled[4:] *= original_height  # y_coords\n\n            coords_pred_scaled = coords_pred.copy()\n            coords_pred_scaled[:4] *= original_width  # x_coords\n            coords_pred_scaled[4:] *= original_height  # y_coords\n\n            x_true = coords_true_scaled[:4]\n            y_true = coords_true_scaled[4:]\n            x_pred = coords_pred_scaled[:4]\n            y_pred = coords_pred_scaled[4:]\n        \n            class_true_idx = np.argmax(labels['class_output'][i].numpy())\n            class_pred_idx = np.argmax(preds_classes[i])\n            class_true_label = label_encoder.inverse_transform([class_true_idx])[0]\n            class_pred_label = label_encoder.inverse_transform([class_pred_idx])[0]\n        \n            fig, ax = plt.subplots(1)\n            ax.imshow(img)\n        \n            ax.plot(x_true, y_true, 'go-', label='Verdadero')\n        \n            ax.plot(x_pred, y_pred, 'ro-', label='Predicho')\n        \n            plt.title(f\"Clase real: {class_true_label}, Clase predicha: {class_pred_label}\")\n            plt.legend()\n            plt.show()\n        \n            images_processed += 1\n    \n        if images_processed >= num_images_to_process:\n            break  # Salir del bucle externo si ya procesamos 5 imágenes","metadata":{"execution":{"iopub.status.busy":"2024-12-05T22:40:29.011566Z","iopub.status.idle":"2024-12-05T22:40:29.011902Z","shell.execute_reply.started":"2024-12-05T22:40:29.011749Z","shell.execute_reply":"2024-12-05T22:40:29.011765Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"visualize_test_predictions(model,test_dataset)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"predictions = model.predict(test_dataset)\npreds_classes = predictions[1]","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-05T22:40:29.013004Z","iopub.status.idle":"2024-12-05T22:40:29.013310Z","shell.execute_reply.started":"2024-12-05T22:40:29.013160Z","shell.execute_reply":"2024-12-05T22:40:29.013176Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"y_true = []\n\n\nfor images, labels in test_dataset:\n    class_labels = labels['class_output'].numpy()\n    class_indices = np.argmax(class_labels, axis=1)\n    y_true.extend(class_indices)\n\ny_true = np.array(y_true)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-05T22:40:29.014154Z","iopub.status.idle":"2024-12-05T22:40:29.014447Z","shell.execute_reply.started":"2024-12-05T22:40:29.014303Z","shell.execute_reply":"2024-12-05T22:40:29.014317Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"y_pred = np.argmax(preds_classes, axis=1)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-05T22:40:29.015590Z","iopub.status.idle":"2024-12-05T22:40:29.015931Z","shell.execute_reply.started":"2024-12-05T22:40:29.015787Z","shell.execute_reply":"2024-12-05T22:40:29.015802Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"from sklearn.metrics import classification_report\n\nclass_labels = label_encoder.classes_\nreport = classification_report(y_true, y_pred, target_names=class_labels)\n\nprint(report)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-05T22:40:29.017625Z","iopub.status.idle":"2024-12-05T22:40:29.017985Z","shell.execute_reply.started":"2024-12-05T22:40:29.017837Z","shell.execute_reply":"2024-12-05T22:40:29.017853Z"}},"outputs":[],"execution_count":null}]}